<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="Content-type" content="text/html; charset=utf-8">
  <title>Zero-shot Graph Embedding</title>
  <style type="text/css" media="screen">
    body {
      background-color: #ffffff;
      margin: 0;
      font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
    }

    .container {
      margin: 50px auto 40px auto;
      width: 900px;
      text-align: center;
    }

    a {
      color: #0db14b;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    h1 {
      width: 900px;
      position: relative;
      letter-spacing: 0px;
      line-height: 60px;
      font-size: 32px;
      font-weight: 100;
      margin: 0px 0 50px 0;
      text-shadow: 0 1px 0 #fff;
    }

    p {
      color: rgba(0, 0, 0, 1);
      margin: 20px 0;
      line-height: 1.6;
      text-align: left;
    }

    ul {
      list-style: none;
      margin: 25px 0;
      padding: 0;
    }

    li {
      display: table-cell;
      font-weight: normal;
      width: 1%;
      align="left";
    }

    .logo {
      display: inline-block;
      margin-top: 35px;
    }

    .logo-img-2x {
      display: none;
    }

    @media only screen and (-webkit-min-device-pixel-ratio: 2),
    only screen and (min--moz-device-pixel-ratio: 2),
    only screen and (-o-min-device-pixel-ratio: 2/1),
    only screen and (min-device-pixel-ratio: 2),
    only screen and (min-resolution: 192dpi),
    only screen and (min-resolution: 2dppx) {
      .logo-img-1x {
        display: none;
      }

      .logo-img-2x {
        display: inline-block;
      }
    }

    #suggestions {
      margin-top: 35px;
      color: #ccc;
    }

    #suggestions a {
      color: #666666;
      font-weight: 200;
      font-size: 14px;
      margin: 0 10px;
    }

    img.grayscale {
      filter: url("data:image/svg+xml;utf8,<svg xmlns=\'http://www.w3.org/2000/svg\'><filter id=\'grayscale\'><feColorMatrix type=\'matrix\' values=\'0.3333 0.3333 0.3333 0 0 0.3333 0.3333 0.3333 0 0 0.3333 0.3333 0.3333 0 0 0 0 0 1 0\'/></filter></svg>#grayscale");
      /* Firefox 3.5+ */
      filter: gray;
      /* IE6-9 */
      -webkit-filter: grayscale(100%);
      /* Chrome 19+ & Safari 6+ */
    }

    img.grayscale:hover {
      filter: none;
      -webkit-filter: grayscale(0%);
    }
  </style>
</head>

<body>

  <div class="container">

    <h1 align="center">Zero-shot Graph Embedding (ZGE)</h1>

    <!-- <p><strong>Students Supported:</strong> </p> -->
    <h2 align="left">Problem definition</h2>
	<img src="../img/zsge.png" width="70%" align="center">
    <p>
	<strong>Zero-shot Graph Embedding (ZGE)</strong> refers to the process of learning discriminative graph embeddings when labeled data cannot cover all classes (also known as completely-imbalanced label setting).
	Here, "zero-shot" means to handle the nodes coming from unseen classes.
	This problem has practical significance, especially when the graph size is typical large and nodes can take on many values.
    </p>
	
    <h2 align="left">Our solution: RSDNE and RECT</h2>
	<p><img src="../img/zsge_result.png" width="100%"></p>
	<p><img src="../img/general_result.png" width="100%"></p>
	<p>
	We propose a shallow method <a href="https://github.com/zhengwang100/RSDNE-python">RSDNE</a> [1] and a GNN method <a href="https://github.com/zhengwang100/RECT">RECT</a> [2]. Our methods generally perform best in this zero-shot label setting.
	Especially, <strong>our RECT outperforms GCN by [20%~300%]</strong>.
	In addition, we note that: even in the balanced label setting, our methods could still achieve comparable performance to state-of-the-art semi-supervised methods.
	Therefore, we always recommend our methods for the scenario where the quality of labels cannot be guaranteed.
	
	<p>
	<strong>Why RECT works?</strong>
        In [3], we show that its core part RECT-L actually learns a prototypical model with the labeled data of seen classes. This reflects its reasonability on seen classes. 
	On the other hand, the learned prototypical model maps the data from the raw-input space into a semantic space, like ZSL methods. 
	As validated by lots of ZSL methods, this enables the success of transferring supervised knowledge of seen classes to unseen classes, indicating its reasonability on unseen classes.


	<h3 align="left">Publications and Codes</h3>
           <ul align="left">
	       <li align="left">[1] Zheng Wang, Xiaojun Ye, Chaokun Wang, and etc. RSDNE: Exploring Relaxed Similarity and Dissimilarity from Completely-imbalanced Labels for Network Embedding. (<strong>AAAI 2018</strong>) [<a class="dhtgD" href="https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16062/15722" target="_blank">PDF</a>, <a class="dhtgD"      href="https://github.com/zhengwang100/RSDNE" target="_blank">CODE-matlab</a>, <a class="dhtgD" href="https://github.com/zhengwang100/RSDNE-python" target="_blank">CODE-python</a>].
               </li><br>
	       <li align="left">[2] Zheng Wang, Xiaojun Ye, Chaokun Wang, Jian Cui, and Philip S. Yu. Network Embedding with Completely-imbalanced Labels. (<strong>TKDE 2020</strong>) [<a class="dhtgD" href="https://zhengwang100.github.io/pdf/TKDE20_wzheng.pdf" target="_blank">PDF</a>, <a class="dhtgD" href="https://github.com/zhengwang100/RECT" target="_blank">CODE</a>].
               </li><br>
	       <li align="left">[3] Zheng Wang and et al. Expanding Semantic Knowledge for Zero-shot Graph Embedding. (<strong>DASFAA 2021</strong>) [<a class="dhtgD" href="https://zhengwang100.github.io/pdf/DASFAA21_wzheng.pdf" target="_blank">PDF</a>].
               </li> <br>
	       <li align="left">[4] Implementations of RECT[TKDE20] in the famous GNN libraries <a href="https://github.com/dmlc/dgl/tree/master/examples/pytorch/rect">DGL</a> and <a href="https://github.com/rusty1s/pytorch_geometric/blob/master/examples/rect.py">PyG</a>.
               </li> <br>
	       <li align="left">[5] Implementations of RECT[TKDE20] in biological deep-learning platform <a href="https://inner.wei-group.net/DeepBIO/">DeepBIO</a>.
               </li> <br>
	       <li align="left">[6] Tutorial on Zero-shot Graph Embedding given in International Young Scholars Forum at RUC <a href="https://zhengwang100.github.io/pdf/ZGE_tutorial_release.pdf">slides</a>.
</li>
           </ul>
		
    </p>
    <!-- <h2 align="left">Existing semi-supervised methods would fail</h2>
	<img src="../img/exist_sge_fail.png" width="80%" align="center">
    <p>
      Existing semi-supervised graph embedding methods would get unappealing results in this setting (typically performance would drop 20%-30%).
	  The reason can be briefly analysed as follows. 
	  To benefit from the discriminative information (e.g., class labels), the most effective and widely used strategy is to guarantee both the intra-class similarity and inter-class dissimilarity in the embedding space. For this purpose, traditional semi-supervised graph embedding methods reduce the intra-class embedding variance and enlarge the inter-class embedding variance by optimizing various classification models. However, as the unseen class nodes are (partly) linked with the seen class ones (i.e., seen and unseen class nodes are correlated), only optimizing over the seen classes is suboptimal for the whole graph.
    </p> -->
    
    <!-- <p>
      Read Code in Wenshuo Zhang's <a href="https://github.com/zwszwszws">respository</a>
    </p> -->
  </div>
</body>

</html>
