<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="Content-type" content="text/html; charset=utf-8">
  <title>Zero-shot Graph Embedding</title>
  <style type="text/css" media="screen">
    body {
      background-color: #ffffff;
      margin: 0;
      font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
    }

    .container {
      margin: 50px auto 40px auto;
      width: 900px;
      text-align: center;
    }

    a {
      color: #0db14b;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    h1 {
      width: 900px;
      position: relative;
      letter-spacing: 0px;
      line-height: 60px;
      font-size: 32px;
      font-weight: 100;
      margin: 0px 0 50px 0;
      text-shadow: 0 1px 0 #fff;
    }

    p {
      color: rgba(0, 0, 0, 1);
      margin: 20px 0;
      line-height: 1.6;
      text-align: left;
    }

    ul {
      list-style: none;
      margin: 25px 0;
      padding: 0;
    }

    li {
      display: table-cell;
      font-weight: normal;
      width: 1%;
      align="left";
    }

    .logo {
      display: inline-block;
      margin-top: 35px;
    }

    .logo-img-2x {
      display: none;
    }

    @media only screen and (-webkit-min-device-pixel-ratio: 2),
    only screen and (min--moz-device-pixel-ratio: 2),
    only screen and (-o-min-device-pixel-ratio: 2/1),
    only screen and (min-device-pixel-ratio: 2),
    only screen and (min-resolution: 192dpi),
    only screen and (min-resolution: 2dppx) {
      .logo-img-1x {
        display: none;
      }

      .logo-img-2x {
        display: inline-block;
      }
    }

    #suggestions {
      margin-top: 35px;
      color: #ccc;
    }

    #suggestions a {
      color: #666666;
      font-weight: 200;
      font-size: 14px;
      margin: 0 10px;
    }

    img.grayscale {
      filter: url("data:image/svg+xml;utf8,<svg xmlns=\'http://www.w3.org/2000/svg\'><filter id=\'grayscale\'><feColorMatrix type=\'matrix\' values=\'0.3333 0.3333 0.3333 0 0 0.3333 0.3333 0.3333 0 0 0.3333 0.3333 0.3333 0 0 0 0 0 1 0\'/></filter></svg>#grayscale");
      /* Firefox 3.5+ */
      filter: gray;
      /* IE6-9 */
      -webkit-filter: grayscale(100%);
      /* Chrome 19+ & Safari 6+ */
    }

    img.grayscale:hover {
      filter: none;
      -webkit-filter: grayscale(0%);
    }
  </style>
</head>

<body>

  <div class="container">

    <h1 align="center">Instruction to Applicants</h1>

    <!-- <p><strong>Students Supported:</strong> </p> -->
    <h2 align="left">Students</h2>
    <p>
	<strong>Zero-shot Graph Embedding (ZGE)</strong> refers to the process of learning discriminative graph embeddings when labeled data cannot cover all classes (also known as completely-imbalanced label setting).
	Here, "zero-shot" means to handle the nodes coming from unseen classes.
	This problem has practical significance, especially when the graph size is typical large and nodes can take on many values.
    </p>
    <p>
    <strong> Reminder:</strong> The prospective students are highly encouraged to request a visit (either offline or online) to my group for 1-2 weeks to get a better understanding about my group. This will help you make good decisions based on transparency.
</p>
    <h2 align="left">Our solution: RSDNE and RECT</h2>
	<p><img src="../img/zsge_result.png" width="100%"></p>
	<p><img src="../img/general_result.png" width="100%"></p>
	<p>
	We propose a shallow method <a href="https://github.com/zhengwang100/RSDNE-python">RSDNE</a> [1] and a GNN method <a href="https://github.com/zhengwang100/RECT">RECT</a> [2]. Our methods generally perform best in this zero-shot label setting.
	Especially, <strong>our RECT outperforms GCN by [20%~300%]</strong>.
	In addition, we note that: even in the balanced label setting, our methods could still achieve comparable performance to state-of-the-art semi-supervised methods.
	Therefore, we always recommend our methods for the scenario where the quality of labels cannot be guaranteed.
	
	<p>
	<strong>Why RECT works?</strong>
        In [3], we show that its core part RECT-L actually learns a prototypical model with the labeled data of seen classes. This reflects its reasonability on seen classes. 
	On the other hand, the learned prototypical model maps the data from the raw-input space into a semantic space, like ZSL methods. 
	As validated by lots of ZSL methods, this enables the success of transferring supervised knowledge of seen classes to unseen classes, indicating its reasonability on unseen classes.
    
    <!-- <p>
      Read Code in Wenshuo Zhang's <a href="https://github.com/zwszwszws">respository</a>
    </p> -->
  </div>
</body>

</html>
